# -*- coding: utf-8 -*-
"""datafest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p4q_HMAh4WZGjbpamvMIE89FSxJT7DHb
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('checkpoints_eoc.csv')
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()
rowCount = len(df)
df.dropna(inplace=True)
df = df.sort_values(by='EOC', ascending=False)
EOCframe = df['EOC']
chapterframe = df['chapter_number']

mean_EOC_by_chapter = df.groupby('chapter_number')['EOC'].mean()

mean_EOC_df = pd.DataFrame(mean_EOC_by_chapter)

mean_EOC_df.reset_index(inplace=True)

print(mean_EOC_df)


sns.lineplot(data=mean_EOC_df, x='chapter_number', y='EOC')



plt.show()




import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('checkpoints_pulse.csv')
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()
rowCount = len(df)
df.dropna(subset=['response'], inplace=True)
df = df.sort_values(by='response', ascending=False)
responseframe = df['response']
chapterframe = df['chapter_number']

unique_values = df['construct'].unique()


c_dataframes = {}


for value in unique_values:
    c_dataframes[value] = df[df['construct'] == value].copy()

Expectancy_df = df[df['construct'] == 'Expectancy']
Cost_df = df[df['construct'] == 'Cost']
Uval_df = df[df['construct'] == 'Utility value']
Ival_df = df[df['construct'] == 'Intrinsic Value']

for value, data in c_dataframes.items():
    sns.relplot(data=data, x='chapter_number', y='response', kind='line', hue='construct', markers=False)



plt.legend()
plt.show()


import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


df = pd.read_csv('checkpoints_pulse.csv')


df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()


df.dropna(subset=['response'], inplace=True)


df.loc[df['construct'] == 'Cost', 'response'] = 5 - df.loc[df['construct'] == 'Cost', 'response']


sns.relplot(data=df, x='chapter_number', y='response', kind='line', hue='construct', ci=None, markers=False)


plt.title('Moral Answers from Students')
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('checkpoints_pulse.csv')
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()
rowCount = len(df)
df.dropna(subset=['response'], inplace=True)
df = df.sort_values(by='response', ascending=False)
responseframe = df['response']
chapterframe = df['chapter_number']

unique_values = df['construct'].unique()


c_dataframes = {}


for value in unique_values:
    c_dataframes[value] = df[df['construct'] == value].copy()

Expectancy_df = df[df['construct'] == 'Expectancy']
Cost_df = df[df['construct'] == 'Cost']
Uval_df = df[df['construct'] == 'Utility value']
Ival_df = df[df['construct'] == 'Intrinsic Value']


for value, data in c_dataframes.items():
    sns.relplot(data=data, x='chapter_number', y='response', kind='line', hue='construct', markers=False)



plt.legend()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


df = pd.read_csv('responses.csv')
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()
df.dropna(subset=['chapter_number', 'section_number'], inplace=True)
df['combined'] = df['chapter_number'] + df['section_number'] / 10

df.dropna(subset=['points_earned', 'points_possible'], inplace=True)
df['PPS'] = df['points_earned'] / df['points_possible']


mean_PPS_by_chapter = df.groupby('combined')['PPS'].mean()
mean_PPS_df = pd.DataFrame(mean_PPS_by_chapter)
mean_PPS_df.reset_index(inplace=True)


plt.figure(figsize=(10, 6))
sns.scatterplot(data=mean_PPS_df, x='combined', y='PPS', color='red', label='Data Points')
sns.regplot(data=mean_PPS_df, x='combined', y='PPS', scatter=False, color='teal', label='Regression Line', ci=None)

unique_chapters = df['chapter_number'].dropna().unique()
plt.xticks(unique_chapters)

plt.xlabel('Chapter')
plt.ylabel('Combined PPS')
plt.title('Mean PPS by Chapter and Section')
plt.legend()
plt.show()

lowest_PPS_rows = df[df['PPS'] < 0.4]


Y = mean_PPS_df['combined']
X = mean_PPS_df['PPS']
X = sm.add_constant(X)
model = sm.OLS(Y,X, missing='drop')
results = model.fit()
results.params

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


df = pd.read_csv('responses.csv')
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()
df.dropna(subset=['chapter_number', 'section_number'], inplace=True)
df['combined'] = df['chapter_number'] + df['section_number'] / 10


mean_attempt_by_chapter = df.groupby('combined')['attempt'].mean()
mean_attempt_df = pd.DataFrame(mean_attempt_by_chapter)
mean_attempt_df.reset_index(inplace=True)

mean_attempt_df = mean_attempt_df[mean_attempt_df['attempt'] <= 2.2]


plt.figure(figsize=(10, 6))
sns.scatterplot(data=mean_attempt_df, x='combined', y='attempt', color='red', label='Data Points')
sns.regplot(data=mean_attempt_df, x='combined', y='attempt', scatter=False, color='teal', label='Regression Line', ci=None)

unique_chapters = df['chapter_number'].dropna().unique()
plt.xticks(unique_chapters)

plt.xlabel('Chapter')
plt.ylabel('Mean Attempts')
plt.title('Mean Attempts by Chapter and Section')
plt.legend()
plt.show()

lowest_PPS_rows = df[df['attempt'] < 0.4]

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('responses.csv')
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()
df.dropna(subset=['chapter_number', 'section_number'], inplace=True)

df.dropna(subset=['points_earned', 'points_possible'], inplace=True)
df['PPS'] = df['points_earned'] / df['points_possible']


mean_PPS_by_chapter = df.groupby(['chapter_number', 'section_number'])['PPS'].mean()
mean_PPS_df = pd.DataFrame(mean_PPS_by_chapter)
mean_PPS_df.reset_index(inplace=True)


plt.figure(figsize=(15, 8))


unique_chapters = df['chapter_number'].unique()
plt.xticks(ticks=range(len(unique_chapters)), labels=unique_chapters)


heatdf = mean_PPS_df.pivot(index='chapter_number', columns='section_number', values='PPS')


sns.heatmap(data=heatdf, cmap='inferno_r', cbar_kws={'label': 'PPS'}, linewidths=0.5, annot=True)

plt.xlabel('Section')
plt.ylabel('Chapter')
plt.title('Heatmap of Mean Score by Chapter and Section: College/Advanced Statistics and Data Science (ABCD)')

plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


df1 = pd.read_csv('responses.csv')
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()
df1.dropna(subset=['chapter_number', 'section_number'], inplace=True)
df1['combined'] = df1['chapter_number'] + df1['section_number'] / 10

df1.dropna(subset=['points_earned', 'points_possible'], inplace=True)
df1['PPS'] = df1['points_earned'] / df1['points_possible']


mean_PPS_by_chapter = df1.groupby('combined')['PPS'].mean()
mean_PPS_df = pd.DataFrame(mean_PPS_by_chapter)
mean_PPS_df.reset_index(inplace=True)


df2 = pd.read_csv('checkpoints_eoc.csv')
df2.dropna(inplace=True)
df2 = df2.sort_values(by='EOC', ascending=False)
mean_EOC_by_chapter = df2.groupby('chapter_number')['EOC'].mean()
mean_EOC_df = pd.DataFrame(mean_EOC_by_chapter)
mean_EOC_df.reset_index(inplace=True)


plt.figure(figsize=(10, 6))


sns.lineplot(data=mean_PPS_df, x='combined', y='PPS', color='red', label='Mean PPS')


sns.scatterplot(data=mean_EOC_df, x='chapter_number', y='EOC', color='blue', label='Mean EOC')

plt.xlabel('Chapter')
plt.ylabel('Mean Value')
plt.title('Mean PPS and EOC by Chapter')
plt.legend()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('page_views.csv')
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()


df.dropna(subset=['off_page_brief', 'off_page_long', 'idle_long', 'idle_brief'], inplace=True)


df['dpp'] = df['off_page_brief'] + df['off_page_long'] + df['idle_long'] + df['idle_brief']
df['combined'] = df['chapter_number'] + df['section_number'] / 10


dts = df.groupby(['combined'])['dpp'].mean().reset_index()


dts = dts[dts['dpp'] != 0]


dts['Mean_DPP_normalized'] = (dts['dpp'] - dts['dpp'].min()) / (dts['dpp'].max() - dts['dpp'].min())


dts = dts.rename(columns={'combined': 'Chapter_Section', 'dpp': 'Mean_DPP'})


sns.lineplot(data=dts, x='Chapter_Section', y='Mean_DPP_normalized', color='blue', label='Mean DPP (Normalized)', ci=None)

plt.xlabel('Chapter_Section')
plt.ylabel('Mean DPP (Normalized)')
plt.title('Mean Disengagement per Section (Normalized)')
plt.legend()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


df = pd.read_csv('page_views.csv')
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()


df.dropna(subset=['off_page_brief', 'off_page_long', 'idle_long', 'idle_brief'], inplace=True)


df['combined'] = df['chapter_number'] + df['section_number'] / 10

df['engaged_normalized'] = (df['engaged'] - df['engaged'].min()) / (df['engaged'].max() - df['engaged'].min())


plt.figure(figsize=(10, 6))
sns.lineplot(data=df, x='combined', y='engaged_normalized', color='blue', label='Engaged', ci=None)

plt.xlabel('Chapter_Section')
plt.ylabel('Engaged (Normalized)')
plt.title('Engagement per Section (Normalized)')
plt.legend()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


df = pd.read_csv('page_views.csv')
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()


df.dropna(subset=['off_page_brief', 'off_page_long', 'idle_long', 'idle_brief'], inplace=True)


df['dpp'] = df['off_page_brief'] + df['off_page_long'] + df['idle_long'] + df['idle_brief']
df['combined'] = df['chapter_number'] + df['section_number'] / 10


dts = df.groupby(['combined'])['dpp'].mean().reset_index()


dts = dts[dts['dpp'] != 0]


dts['Mean_DPP_normalized'] = (dts['dpp'] - dts['dpp'].min()) / (dts['dpp'].max() - dts['dpp'].min())


dts = dts.rename(columns={'combined': 'Chapter_Section', 'dpp': 'Mean_DPP'})


df['engaged_normalized'] = (df['engaged'] - df['engaged'].min()) / (df['engaged'].max() - df['engaged'].min())


variability_factor = 35
df['engaged_normalized'] *= variability_factor


plot_data = pd.merge(dts[['Chapter_Section', 'Mean_DPP_normalized']], df[['combined', 'engaged_normalized']], left_on='Chapter_Section', right_on='combined', how='left')

plt.figure(figsize=(12, 8))

# Plot the mean DPP (normalized)
sns.lineplot(data=plot_data, x='Chapter_Section', y='Mean_DPP_normalized', color='blue', label='Mean Disengagement (Normalized)', ci=None)

# Plot the engagement (normalized)
sns.lineplot(data=plot_data, x='Chapter_Section', y='engaged_normalized', color='orange', label='Engaged (Normalized)', ci=None)

plt.xlabel('Section')
plt.ylabel('Normalized Value')
plt.title('Mean Disengagement and Engagement per Section')
plt.legend()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


df = pd.read_csv('media_views.csv')


df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)']


df['combined'] = df['chapter_number'] + df['section_number'] / 10


sns.barplot(data=df, x='combined', y='proportion_video', palette='inferno', errorbar=None)

plt.xlabel('Chapter & Section')
plt.ylabel('Proportion of Video Views')
plt.title('Proportion of Video Views by Chapter & Section')


plt.ylim(0.5, 0.7)  # Set the lower limit to 0.5

plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


dfi = pd.read_csv('items.csv')
dfi = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()


df = pd.read_csv('checkpoints_pulse.csv')
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()
rowCount = len(df)

df.dropna(subset=['response'], inplace=True)
df = df.sort_values(by='response', ascending=False)
responseframe = df['response']
chapterframe = df['chapter_number']

unique_values = df['construct'].unique()


c_dataframes = {}


for value in unique_values:
    c_dataframes[value] = df[df['construct'] == value].copy()

Expectancy_df = df[df['construct'] == 'Expectancy']
Cost_df = df[df['construct'] == 'Cost']
Uval_df = df[df['construct'] == 'Utility value']
Ival_df = df[df['construct'] == 'Intrinsic Value']


for value, data in c_dataframes.items():
    sns.relplot(data=data, x='chapter_number', y='response', kind='line', hue='construct', markers=False)



plt.legend()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


dfi = pd.read_csv('items.csv')
dfi['combined'] = df['chapter_number'] + df['section_number'] / 10
df = pd.read_csv('media_views.csv')


df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)']


unique_lrn_types = dfi['lrn_type'].unique()


for lrn_type in unique_lrn_types:
    
    lrn_type_df = dfi[dfi['lrn_type'] == lrn_type]

    
    plt.figure(figsize=(12, 6))
    sns.scatterplot(data=lrn_type_df, x='combined', y='lrn_type', label=lrn_type)

    plt.xlabel('combined')
    plt.ylabel('lrn_type')
    plt.title(f'Occurrences of "{lrn_type}" by Chapter')
    plt.legend()
    plt.tight_layout()
    plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


dfi = pd.read_csv('items.csv')
df = pd.read_csv('responses.csv')


df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)']

# Calculate the combined value
df['combined'] = df['chapter_number'] + df['section_number'] / 10

# Merge the DataFrames on 'class_id'
merged_df = pd.merge(df, dfi[['class_id', 'lrn_type']], on='class_id', how='inner')

#Group by both 'combined' and 'lrn_type', then count occurrences
lrn_type_counts = merged_df.groupby(['combined', 'lrn_type']).size().reset_index(name='count')

#calculate the total count for each 'combined' value
combined_total_counts = lrn_type_counts.groupby('combined')['count'].transform('sum')

#calculate the percentage of each 'lrn_type' for each 'combined' value
lrn_type_counts['percent'] = (lrn_type_counts['count'] / combined_total_counts) * 100

#plotting percentage of occurrences of each 'lrn_type' for each 'combined' value
plt.figure(figsize=(12, 6))  # Adjust the figure size as needed
sns.barplot(data=lrn_type_counts, x='combined', y='percent', hue='lrn_type')

# Set y-axis limit to 100
plt.ylim(0, 100)

plt.xlabel('Combined Value')
plt.ylabel('Percentage (%)')
plt.title('Percentage of Each lrn_type for Each Combined Value')
plt.legend(title='lrn_type')
plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


df = pd.read_csv('responses.csv')


df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)']


df['combined'] = df['chapter_number'] + df['section_number'] / 10




lrn_type_counts = df.groupby(['combined', 'lrn_type']).size().reset_index(name='count')


combined_total_counts = lrn_type_counts.groupby('combined')['count'].transform('sum')


lrn_type_counts['percent'] = (lrn_type_counts['count'] / combined_total_counts) * 100

df.dropna(subset=['points_earned', 'points_possible'], inplace=True)
df['PPS'] = df['points_earned'] / df['points_possible']
mean_PPS_by_chapter = df.groupby('combined')['PPS'].mean()
mean_PPS_df = pd.DataFrame(mean_PPS_by_chapter)
mean_PPS_df.reset_index(inplace=True)


plt.figure(figsize=(12, 6))
sns.barplot(data=lrn_type_counts, x='combined', y='percent', hue='lrn_type')

# Set y-axis limit to 100
plt.ylim(0, 100)

plt.xlabel('Combined Value')
plt.ylabel('Percentage (%)')
plt.title('Percentage of Each lrn_type for Each Combined Value')
plt.legend(title='lrn_type')
plt.tight_layout()
plt.show()

import pandas as pd

df = pd.read_csv('responses.csv')

# Filter the responses DataFrame for the specified book
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()

# Drop rows with missing chapter and section numbers
df.dropna(subset=['chapter_number', 'section_number'], inplace=True)

# Calculate the combined value
df['combined'] = df['chapter_number'] + df['section_number'] / 10

# Drop rows with missing points_earned and points_possible
df.dropna(subset=['points_earned', 'points_possible'], inplace=True)

# Calculate the mean PPS by combined chapter and section
df['PPS'] = df['points_earned'] / df['points_possible']
mean_PPS_by_chapter = df.groupby('combined')['PPS'].mean()
mean_PPS_df = pd.DataFrame(mean_PPS_by_chapter)
mean_PPS_df.reset_index(inplace=True)

# Sort the mean PPS DataFrame by the lowest PPS first
mean_PPS_df.sort_values(by='PPS', inplace=True)

# Calculate the count of each lrn_type for each combined
lrn_type_counts = df.groupby(['combined', 'lrn_type']).size().reset_index(name='lrn_type_count')

average_counts = lrn_type_counts.groupby('lrn_type')['lrn_type_count'].mean().reset_index(name='lrn_type_count_average')

# Merge the count DataFrame with the average counts
lrn_type_counts = pd.merge(lrn_type_counts, average_counts, on='lrn_type')

# Calculate the ratio of each lrn_type count to its average count
lrn_type_counts['ratio'] = lrn_type_counts['lrn_type_count'] / lrn_type_counts['lrn_type_count_average']

# Find the mode_lrn_type for each 'combined' based on the lrn_type with the highest ratio
mode_lrn_type = lrn_type_counts.loc[lrn_type_counts.groupby('combined')['ratio'].idxmax()]

# Merge with mean PPS DataFrame
table_df = pd.merge(mean_PPS_df, mode_lrn_type[['combined', 'lrn_type']], on='combined')

# Display the table sorted by lowest to highest PPS
print(table_df)

import pandas as pd

df = pd.read_csv('responses.csv')

# Filter the responses DataFrame for the specified book
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()

# Drop rows with missing chapter and section numbers
df.dropna(subset=['chapter_number', 'section_number'], inplace=True)

# Drop rows with missing points_earned and points_possible
# df.dropna(subset=['points_earned', 'points_possible'], inplace=True)

# Calculate the mean PPS by section and chapter
df['PPS'] = df['points_earned'] / df['points_possible']
mean_PPS_by_section_chapter = df.groupby(['chapter_number', 'section_number'])['PPS'].mean()
mean_PPS_df = pd.DataFrame(mean_PPS_by_section_chapter)
mean_PPS_df.reset_index(inplace=True)

# Sort the mean PPS DataFrame by the lowest PPS first
mean_PPS_df.sort_values(by='PPS', inplace=True)

lrn_type_counts = df.groupby(['chapter_number', 'section_number', 'lrn_type']).size().reset_index(name='lrn_type_count')

average_counts = lrn_type_counts.groupby(['chapter_number', 'section_number', 'lrn_type'])['lrn_type_count'].mean().reset_index(name='lrn_type_count_average')

# Merge the count DataFrame with the average counts
lrn_type_counts = pd.merge(lrn_type_counts, average_counts, on=['chapter_number', 'section_number', 'lrn_type'])

# Calculate the ratio of each lrn_type count to its average count
lrn_type_counts['ratio'] = lrn_type_counts['lrn_type_count'] / lrn_type_counts['lrn_type_count_average']

# Find the mode_lrn_type for each section and chapter combination based on the lrn_type with the highest ratio
mode_lrn_type = lrn_type_counts.loc[lrn_type_counts.groupby(['chapter_number', 'section_number'])['ratio'].idxmax()]

# Merge with mean PPS DataFrame
table_df = pd.merge(mean_PPS_df, mode_lrn_type[['chapter_number', 'section_number', 'lrn_type']], on=['chapter_number', 'section_number'])


# Filter out rows where PPS is NaN
table_df = table_df.dropna(subset=['PPS'])

# Display the table sorted by lowest to highest PPS
print(table_df.head(32))

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('responses.csv')

# Filter the responses DataFrame for the specified book
df = df[df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()

# Drop rows with missing chapter and section numbers
df.dropna(subset=['chapter_number', 'section_number'], inplace=True)

# Calculate the mean PPS by section and chapter
df['PPS'] = df['points_earned'] / df['points_possible']

# Calculate the average PPS for each lrn_type
average_PPS_by_lrn_type = df.groupby('lrn_type')['PPS'].mean()

# Plotting the bar graph
plt.figure(figsize=(10, 6))
average_PPS_by_lrn_type.plot(kind='bar', color='skyblue')
plt.xlabel('Learning Type')
plt.ylabel('Average PPS')
plt.title('Average PPS by Learning Type')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Read the responses CSV file into a DataFrame
responses_df = pd.read_csv('responses.csv')

# Filter the responses DataFrame for the specified book
responses_df = responses_df[responses_df['book'] == 'College / Advanced Statistics and Data Science (ABCD)'].copy()

# Drop rows with missing chapter and section numbers
responses_df.dropna(subset=['chapter_number', 'section_number'], inplace=True)

# Read the 'checkpoints_eoc' file containing only the 'EOC' column
eoc_df = pd.read_csv('checkpoints_eoc.csv')

# Merge the 'EOC' column with the responses DataFrame based on the chapter_number
merged_df = pd.merge(responses_df, eoc_df, left_on='chapter_number', right_index=True)

# Find the most common learning type for each chapter
mode_lrn_type_by_chapter = merged_df.groupby('chapter_number')['lrn_type'].agg(lambda x: x.mode()).reset_index(name='mode_lrn_type')

# Merge the mode learning type with the merged DataFrame
merged_df = pd.merge(merged_df, mode_lrn_type_by_chapter, on='chapter_number')

# Calculate the average EOC for each chapter
average_eoc_by_chapter = merged_df.groupby('chapter_number')['EOC'].mean()

plt.figure(figsize=(12, 8))
plt.bar(average_eoc_by_chapter.index, average_eoc_by_chapter.values, color='skyblue', label='EOC')
plt.bar(merged_df['chapter_number'], merged_df['mode_lrn_type'], color='lightgreen', alpha=0.7, label='Most Common Learning Type')
plt.xlabel('Chapter')
plt.ylabel('Value')
plt.title('Average EOC and Most Common Learning Type by Chapter')
plt.xticks(rotation=45, ha='right')
plt.legend()
plt.tight_layout()
plt.show()
